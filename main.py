import requests
import random
from bs4 import BeautifulSoup
import time
import logging
from io import BytesIO
import re
import concurrent.futures
import sys
import locale

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ —Å–∏—Å—Ç–µ–º—ã
try:
    locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')
except:
    pass

sys.stdout.reconfigure(encoding='utf-8') if hasattr(sys.stdout, 'reconfigure') else None
sys.stderr.reconfigure(encoding='utf-8') if hasattr(sys.stderr, 'reconfigure') else None

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫–∏ UTF-8
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# –°–æ–∑–¥–∞–µ–º —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π UTF-8
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

# –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π –≤—ã–≤–æ–¥
console_handler = logging.StreamHandler()
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)

# –§–∞–π–ª–æ–≤—ã–π –≤—ã–≤–æ–¥ —Å UTF-8
try:
    file_handler = logging.FileHandler("proxy_parser.log", encoding='utf-8')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
except Exception as e:
    logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤–æ–≥–æ –ª–æ–≥–≥–µ—Ä–∞: {str(e)}")

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Accept-Language": "en-US,en;q=0.5",
    "Connection": "keep-alive",
    "Upgrade-Insecure-Requests": "1"
}

MAX_RETRIES = 1000
TIMEOUT = 30
BASE_URL = "https://infostart.ru/1c/articles/"
MAX_PROXY_RETRIES = 10
PROXY_CHECK_URL = "http://httpbin.org/ip"
PROXY_SOURCES = [
    "https://api.proxyscrape.com/v2/?request=getproxies&protocol=http&timeout=5000&country=all&ssl=all&anonymity=all",
    "https://raw.githubusercontent.com/TheSpeedX/PROXY-List/master/http.txt",
    "https://raw.githubusercontent.com/ShiftyTR/Proxy-List/master/http.txt",
    "https://raw.githubusercontent.com/jetkai/proxy-list/main/online-proxies/txt/proxies-http.txt"
]

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Telegram ---
TELEGRAM_TOKEN = "8114950949:AAF_pK08B4IL17I0PgKthvLvqmxeRWmOA4w"
TELEGRAM_CHAT = "@VsratiyIS"
TELEGRAM_API = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto"

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Hugging Face ---
HF_API_URL = "https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-base"
HF_TOKEN = "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"
HF_TIMEOUT = 60

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ–∫—Å–∏
WORKING_PROXIES = []
LAST_PROXY_UPDATE = 0
PROXY_UPDATE_INTERVAL = 1800  # 30 –º–∏–Ω—É—Ç

# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø—Ä–æ–∫—Å–∏ ---
def update_proxy_list():
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ–∫—Å–∏ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    global WORKING_PROXIES, LAST_PROXY_UPDATE
    
    if time.time() - LAST_PROXY_UPDATE < PROXY_UPDATE_INTERVAL and WORKING_PROXIES:
        return
    
    logger.info("üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø—Ä–æ–∫—Å–∏...")
    all_proxies = []
    
    for source in PROXY_SOURCES:
        try:
            response = requests.get(source, timeout=15)
            if response.status_code == 200:
                proxies = re.findall(r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d+', response.text)
                all_proxies.extend(proxies)
                logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(proxies)} –ø—Ä–æ–∫—Å–∏ –∏–∑ {source}")
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–æ–∫—Å–∏ –∏–∑ {source}: {str(e)}")
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    all_proxies = list(set(all_proxies))
    logger.info(f"–í—Å–µ–≥–æ –ø–æ–ª—É—á–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏: {len(all_proxies)}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –ø—Ä–æ–∫—Å–∏
    if all_proxies:
        WORKING_PROXIES = check_proxies(all_proxies)
        LAST_PROXY_UPDATE = time.time()
        logger.info(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ–∫—Å–∏: {len(WORKING_PROXIES)}")
    else:
        logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏")

def check_proxy(proxy):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –æ–¥–Ω–æ–≥–æ –ø—Ä–æ–∫—Å–∏"""
    proxy_url = f"http://{proxy}"
    proxies = {"http": proxy_url, "https": proxy_url}
    
    try:
        start_time = time.time()
        response = requests.get(
            PROXY_CHECK_URL,
            proxies=proxies,
            timeout=10,
            headers=HEADERS
        )
        if response.status_code == 200:
            speed = time.time() - start_time
            return proxy, speed
    except Exception:
        pass
    return None

def check_proxies(proxies, max_workers=50):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏ –Ω–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç–∏"""
    valid_proxies = []
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(check_proxy, proxy) for proxy in proxies]
        
        for future in concurrent.futures.as_completed(futures):
            result = future.result()
            if result:
                proxy, speed = result
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ–∫—Å–∏
                if speed < 5.0:
                    valid_proxies.append(proxy)
    
    return valid_proxies

def get_random_proxy():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π —Ä–∞–±–æ—á–∏–π –ø—Ä–æ–∫—Å–∏"""
    if not WORKING_PROXIES:
        update_proxy_list()
    
    if WORKING_PROXIES:
        return random.choice(WORKING_PROXIES)
    return None

def make_request(url, method="GET", timeout=TIMEOUT, retries=MAX_PROXY_RETRIES):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ —Å–ª—É—á–∞–π–Ω—ã–π —Ä–∞–±–æ—á–∏–π –ø—Ä–æ–∫—Å–∏"""
    for attempt in range(retries):
        proxy = get_random_proxy()
        if not proxy:
            logger.error("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ–∫—Å–∏")
            time.sleep(10)
            continue
            
        proxy_url = f"http://{proxy}"
        proxies = {"http": proxy_url, "https": proxy_url}
        
        try:
            logger.info(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt+1}/{retries} —Å –ø—Ä–æ–∫—Å–∏: {proxy}")
            
            if method == "GET":
                response = requests.get(
                    url, 
                    headers=HEADERS, 
                    proxies=proxies, 
                    timeout=timeout
                )
            elif method == "HEAD":
                response = requests.head(
                    url, 
                    headers=HEADERS, 
                    proxies=proxies, 
                    timeout=timeout
                )
            else:
                response = requests.request(
                    method,
                    url, 
                    headers=HEADERS, 
                    proxies=proxies, 
                    timeout=timeout
                )
            
            if response.status_code == 200:
                return response
            else:
                logger.warning(f"–û—à–∏–±–∫–∞ {response.status_code} –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {url}")
        except requests.exceptions.ProxyError:
            # –£–¥–∞–ª—è–µ–º –Ω–µ—Ä–∞–±–æ—á–∏–π –ø—Ä–æ–∫—Å–∏ –∏–∑ —Å–ø–∏—Å–∫–∞
            if proxy in WORKING_PROXIES:
                WORKING_PROXIES.remove(proxy)
                logger.warning(f"–£–¥–∞–ª–µ–Ω –Ω–µ—Ä–∞–±–æ—á–∏–π –ø—Ä–æ–∫—Å–∏: {proxy}")
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {str(e)}")
        
        time.sleep(random.uniform(1, 3))
    
    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ {retries} –ø–æ–ø—ã—Ç–æ–∫")
    return None

# --- –§—É–Ω–∫—Ü–∏—è: –ø–æ–ª—É—á–∏—Ç—å URL —Å–ª—É—á–∞–π–Ω–æ–π —Å—Ç–∞—Ç—å–∏ ---
def get_random_article_url():
    """–ù–∞—Ö–æ–¥–∏—Ç —Å–ª—É—á–∞–π–Ω—É—é —Ä–∞–±–æ—á—É—é —Å—Ç–∞—Ç—å—é —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏"""
    for attempt in range(MAX_RETRIES):
        article_id = random.randint(1, 2000000)
        url = f"{BASE_URL}{article_id}/"
        logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—å–∏ #{article_id}")
        
        response = make_request(url)
        if response and response.status_code == 200:
            logger.info(f"‚úÖ –°—Ç–∞—Ç—å—è –Ω–∞–π–¥–µ–Ω–∞: {url}")
            return url
        
        # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏
        time.sleep(random.uniform(0.5, 2))
    
    logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–æ—Å—Ç—É–ø–Ω—É—é —Å—Ç–∞—Ç—å—é")
    return None

# --- –§—É–Ω–∫—Ü–∏—è: –Ω–∞–π—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ ---
def get_images_from_article(url):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ —Å—Ç–∞—Ç—å–∏ —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏"""
    try:
        response = make_request(url)
        if not response or response.status_code != 200:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É: {url}")
            return []

        soup = BeautifulSoup(response.text, 'html.parser')
        image_urls = []

        # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Å—Ç–∞—Ç—å–µ
        for img in soup.find_all('img', src=True):
            src = img.get('src', '')
            if src:
                if src.startswith(('http://', 'https://')):
                    image_urls.append(src)
                elif src.startswith('/'):
                    image_urls.append(f"https://infostart.ru{src}")
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        filtered = [
            img for img in image_urls 
            if 'infostart.ru' in img 
            and 'no_avatar_forum' not in img
            and any(img.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.webp'])
        ]
        return list(set(filtered))
    except Exception as e:
        logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {e}", exc_info=True)
        return []

# --- –§—É–Ω–∫—Ü–∏—è: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ---
def generate_image_caption(image_url):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Hugging Face API"""
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏
        response = make_request(image_url)
        if not response or response.status_code != 200:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_url}")
            return None
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if len(response.content) > 3 * 1024 * 1024:  # 3 MB
            logger.warning(f"‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ: {len(response.content)//1024} KB")
            return None
            
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è Hugging Face
        headers = {"Authorization": f"Bearer {HF_TOKEN}"}
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–∏–Ω–∞—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        response_hf = requests.post(
            HF_API_URL,
            headers=headers,
            data=response.content,
            timeout=HF_TIMEOUT
        )
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
        if response_hf.status_code == 200:
            result = response_hf.json()
            if isinstance(result, list) and len(result) > 0:
                caption = result[0].get('generated_text', '')
                logger.info(f"ü§ñ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ: {caption}")
                return caption
                
        elif response_hf.status_code == 503:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª—É—á–∞—è, –∫–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è
            try:
                error_data = response_hf.json()
                estimated_time = error_data.get('estimated_time', 30)
                logger.info(f"‚è≥ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è, –æ–∂–∏–¥–∞–µ–º {estimated_time} —Å–µ–∫—É–Ω–¥...")
                time.sleep(estimated_time + 5)
                return generate_image_caption(image_url)  # –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞
            except:
                time.sleep(30)
                return None
                
        else:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ Hugging Face ({response_hf.status_code}): {response_hf.text}")
            
    except Exception as e:
        logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏—è: {e}", exc_info=True)
    return None

# --- –§—É–Ω–∫—Ü–∏—è: –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ –≤ Telegram ---
def send_image_to_telegram(image_url, article_url):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ Telegram —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º"""
    if not is_valid_image(image_url):
        return

    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏
        response = make_request(image_url)
        if not response or response.status_code != 200:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_url}")
            return
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with BytesIO() as buffer:
            buffer.write(response.content)
            buffer.seek(0)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é
            ai_caption = generate_image_caption(image_url)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
            caption = f"üìå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ —Å—Ç–∞—Ç—å–∏:\n{article_url}"
            if ai_caption:
                caption += f"\n\nü§ñ –û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é:\n{ai_caption}"
            
            # –û–±—Ä–µ–∑–∞–µ–º –¥–æ 1024 —Å–∏–º–≤–æ–ª–æ–≤
            caption = caption[:1024]

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Telegram
            files = {'photo': buffer}
            data = {'chat_id': TELEGRAM_CHAT, 'caption': caption}
            
            tg_response = requests.post(
                TELEGRAM_API,
                data=data,
                files=files,
                timeout=20
            )
            
            if tg_response.status_code == 200:
                logger.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram")
            else:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ Telegram ({tg_response.status_code}): {tg_response.text}")
            
    except Exception as e:
        logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {e}", exc_info=True)

def is_valid_image(url):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ HEAD-–∑–∞–ø—Ä–æ—Å"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        clean_url = url.split('?')[0].lower()
        if not any(clean_url.endswith(ext) for ext in ('.jpg', '.jpeg', '.png', '.webp')):
            logger.warning(f"üö´ –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {url}")
            return False
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ HEAD-–∑–∞–ø—Ä–æ—Å
        response = make_request(url, method="HEAD", timeout=5)
        if not response:
            return False
            
        content_length = response.headers.get('Content-Length')
        if content_length and int(content_length) > 10 * 1024 * 1024:  # 10 MB
            logger.warning(f"üö´ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ: {int(content_length)//1024} KB")
            return False
            
        return True
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
        return False

# --- –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª ---
def main():
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ —Å –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π –ø—Ä–æ–∫—Å–∏...")
    sent_count = 0
    update_proxy_list()  # –ù–∞—á–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø—Ä–æ–∫—Å–∏

    while True:
        try:
            logger.info("\n" + "="*50)
            logger.info("üîç –ü–æ–∏—Å–∫ –Ω–æ–≤–æ–π —Å—Ç–∞—Ç—å–∏ —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏...")
            article_url = get_random_article_url()
            if not article_url:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å—Ç–∞—Ç—å—é. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 10 —Å–µ–∫—É–Ω–¥...")
                time.sleep(10)
                continue

            logger.info(f"üìÑ –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç—å–∏: {article_url}")
            images = get_images_from_article(article_url)
            logger.info(f"üì∑ –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(images)}")

            if images:
                for img in images:
                    try:
                        logger.info(f"üñºÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {img}")
                        send_image_to_telegram(img, article_url)
                        sent_count += 1
                        logger.info(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {sent_count}")
                        time.sleep(random.uniform(2, 5))  # –°–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                    except Exception as e:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}", exc_info=True)
                
                logger.info(f"üì§ –í—Å–µ–≥–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {sent_count}")
                logger.info("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ 5 –º–∏–Ω—É—Ç –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç–∞—Ç—å–µ–π...")
                time.sleep(300)  # –î–ª–∏—Ç–µ–ª—å–Ω–∞—è –ø–∞—É–∑–∞ –ø–æ—Å–ª–µ —Å—Ç–∞—Ç—å–∏
            else:
                logger.warning("üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
                time.sleep(10)

        except KeyboardInterrupt:
            logger.info("üõë –ü—Ä–æ–≥—Ä–∞–º–º–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            break
        except Exception as e:
            logger.critical(f"üî• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
            time.sleep(30)
            
            # –ü—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–µ –æ–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–∫—Å–∏
            update_proxy_list()

if __name__ == "__main__":
    main()
